{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f0aa677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "import pdfplumber\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from pathlib import Path\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"shibing624/text2vec-base-chinese\")\n",
    "\n",
    "\"\"\"\n",
    "返回以不同pdf文件分隔的embedding db\n",
    "传入参数：pdf文件路径列表，list[str]\n",
    "返回：embedding FAISS db\n",
    "\"\"\"\n",
    "def get_pdf_embedding(pdf_path_list):\n",
    "    list_of_documents = []\n",
    "    for idx, pdf_path in enumerate(pdf_path_list):\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            path = Path(pdf_path)\n",
    "            filename = path.name\n",
    "            text = \"\"\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                text += page.extract_text()\n",
    "            list_of_documents.append(Document(page_content=text, metadata=dict(file_name=filename, pdf_num=idx)))\n",
    "    return FAISS.from_documents(list_of_documents, embeddings)     \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "返回以页数分隔的embedding db\n",
    "传入参数：pdf文件路径列表，list[str]\n",
    "返回：embedding FAISS db\n",
    "\"\"\"\n",
    "def get_pdf_embedding_paging(pdf_path_list):\n",
    "    list_of_documents = []\n",
    "    for idx, pdf_path in enumerate(pdf_path_list):\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            path = Path(pdf_path)\n",
    "            filename = path.name\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                curr_text = page.extract_text()\n",
    "                list_of_documents.append(Document(page_content=curr_text[:len(curr_text)//2], metadata=dict(file_name=filename, pdf_num=idx, page_num=i, chunk_num=0)))\n",
    "                list_of_documents.append(Document(page_content=curr_text[len(curr_text)//2:], metadata=dict(file_name=filename, pdf_num=idx, page_num=i, chunk_num=1)))\n",
    "    return FAISS.from_documents(list_of_documents, embeddings)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b87554c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path_list = [\"./pdfs/公正--该如何做是好.pdf\", \"./pdfs/功利主义.pdf\", \"./pdfs/诉公共卫生部案.pdf\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fceda13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pdf_embedding_paging(pdf_path_list).save_local(\"faiss_pdf_embedding_paging\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90a7ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pdf_embedding(pdf_path_list).save_local(\"faiss_pdf_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38ab8562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_with_scores = db.similarity_search_with_score(\"同性恋起诉公共卫生部案\")\n",
    "# for doc, score in results_with_scores:\n",
    "#     print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}, Score: {score}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8e90968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from pytube import YouTube\n",
    "\"\"\"\n",
    "分割列表utils函数\n",
    "\"\"\"\n",
    "def chunk_list(input_list, chunk_size=50):\n",
    "    return [input_list[i:i + chunk_size] for i in range(0, len(input_list), chunk_size)]\n",
    "\n",
    "\"\"\"\n",
    "获取视频title utils函数\n",
    "\"\"\"\n",
    "def get_title(video_id):\n",
    "    url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "    yt = YouTube(url)\n",
    "    return yt.title\n",
    "\n",
    "\"\"\"\n",
    "返回YouTube字幕的embedding FAISS db，分页\n",
    "传入参数：YouTube Video Id列表，list[str]\n",
    "返回：embedding FAISS db\n",
    "\"\"\"\n",
    "def get_youtube_embedding_paging(video_id_list):\n",
    "    list_of_documents = []\n",
    "    for video_id in video_id_list:\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "        for transcript in transcript_list:\n",
    "            if transcript.language != 'English (auto-generated)':\n",
    "                continue\n",
    "            transcript_list = transcript.translate('zh-Hans').fetch()\n",
    "            chunked_lists = chunk_list(transcript_list, 25)\n",
    "            for t in chunked_lists:\n",
    "                text = \"\".join(obj['text'] for obj in t)\n",
    "                time = t[0]['start']\n",
    "                list_of_documents.append(Document(page_content=text, metadata=dict(video_name=get_title(video_id), start_time=time, video_id=video_id)))\n",
    "    return FAISS.from_documents(list_of_documents, embeddings)\n",
    "\n",
    "\"\"\"\n",
    "返回YouTube字幕的embedding FAISS db，不分页\n",
    "传入参数：YouTube Video Id列表，list[str]\n",
    "返回：embedding FAISS db\n",
    "\"\"\"\n",
    "def get_youtube_embedding(video_id_list):\n",
    "    list_of_documents = []\n",
    "    for video_id in video_id_list:\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "        for transcript in transcript_list:\n",
    "            if transcript.language != 'English (auto-generated)':\n",
    "                continue\n",
    "            transcript_list = transcript.translate('zh-Hans').fetch()\n",
    "            text = \"\".join(obj['text'] for obj in transcript_list)\n",
    "            list_of_documents.append(Document(page_content=text, metadata=dict(video_name=get_title(video_id))))\n",
    "    return FAISS.from_documents(list_of_documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fd515c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARDCODED: Harvard课程 https://www.youtube.com/playlist?list=PL30C13C91CFFEFEA6\n",
    "video_id_list = ['kBdfcR-8hEY', \n",
    "                 '0O2Rq4HJBxw', \n",
    "                 'Qw4l1w0rkjs', \n",
    "                 'MGyygiXMzRk', \n",
    "                 '8yT4RZy1t3s', \n",
    "                 '8rv-4aUbZxQ', \n",
    "                 'KqzW0eHzDSQ', \n",
    "                 'VcL66zx_6No', \n",
    "                 'AUhReMT5uqA', \n",
    "                 'MuiazbyOSqQ', \n",
    "                 'iOotE9_OGGs', \n",
    "                 'EzD9P-9sj4M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29513638",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_youtube_embedding(video_id_list).save_local(\"faiss_youtube_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9d41f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_youtube_embedding_paging(video_id_list).save_local(\"faiss_youtube_embedding_paging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1028ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_with_scores = db2.similarity_search_with_score(\"个人权利与政府权力\")\n",
    "# for doc, score in results_with_scores:\n",
    "#     print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}, Score: {score}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52f8318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b028a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
